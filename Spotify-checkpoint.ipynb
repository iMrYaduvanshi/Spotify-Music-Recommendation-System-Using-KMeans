{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a19a9fe-8ec8-4039-a0ea-6e5cc3422bde",
   "metadata": {},
   "source": [
    "Load Spotify Dataset And Necessary Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fcedf3-38e7-4bff-bcbf-b676dc82a26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "df=pd.read_csv(r\"E:\\30 day datascience\\SpotifyFeatures.csv\")\n",
    "print(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e10e25-42b8-4429-87d5-c74c040eb3eb",
   "metadata": {},
   "source": [
    "Check For Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afba1aa2-d1f1-45e6-9e2c-488125cc6cb2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m missing_data=\u001b[43mdf\u001b[49m.isnull().sum()\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(missing_data)\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "missing_data=df.isnull().sum()\n",
    "print(missing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fbdae7-0420-4b67-bc59-66868440717d",
   "metadata": {},
   "source": [
    "Fill the Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333dc53f-1fe3-4d4d-a34e-3caa84693d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['track_name']=df['track_name'].fillna(df['track_name'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222c8c73-e746-4151-b9c8-6850427b5c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2a2fc8-6b7d-4e08-a6b1-74c33bbe1c05",
   "metadata": {},
   "source": [
    "Detecting Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c303ee-684e-465f-a0e8-abba84bdfb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df[['acousticness', 'danceability', 'energy', \n",
    "               'instrumentalness', 'liveness', 'loudness', \n",
    "               'speechiness', 'tempo', 'valence']]\n",
    "Q1 = features.quantile(0.25)\n",
    "Q3 = features.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Identify outliers beyond 1.5 * IQR\n",
    "outliers = ((features < (Q1 - 1.5 * IQR)) | (features > (Q3 + 1.5 * IQR))).sum()\n",
    "print(outliers)\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee0f0fd-c388-4ce5-876c-c0f249bccacf",
   "metadata": {},
   "source": [
    "Filtering Dataset From Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcfdb9c-cb72-4f74-9fb0-e060617ea37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of features to check for outliers\n",
    "features = ['acousticness', 'danceability', 'energy', \n",
    "            'instrumentalness', 'liveness', 'loudness', \n",
    "            'speechiness', 'tempo', 'valence']\n",
    "\n",
    "# Loop over the columns and remove outliers using IQR\n",
    "filtered_df = df.copy()\n",
    "\n",
    "for col in features:\n",
    "    # Calculate Q1, Q3, and IQR for the feature\n",
    "    Q1 = filtered_df[col].quantile(0.25)\n",
    "    Q3 = filtered_df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Calculate lower and upper bounds for detecting outliers\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Remove rows where values are outside the bounds\n",
    "    filtered_df = filtered_df[(filtered_df[col] >= lower_bound) & (filtered_df[col] <= upper_bound)]\n",
    "\n",
    "# Print the size of the original and filtered dataframe\n",
    "print(f\"Original dataset size: {df.shape[0]}\")\n",
    "print(f\"Dataset size after removing outliers: {filtered_df.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b861bf-ea27-4ff2-8119-f421aa4571b7",
   "metadata": {},
   "source": [
    "Scaling The Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae58fcf-662f-4b28-8cfd-bdc5de9f2656",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Selecting features after outlier removal\n",
    "features = ['acousticness', 'danceability', 'energy', \n",
    "            'instrumentalness', 'liveness', 'loudness', \n",
    "            'speechiness', 'tempo', 'valence']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(filtered_df[features])\n",
    "\n",
    "# Optional: Convert back to DataFrame for easier handling\n",
    "df_scaled = pd.DataFrame(scaled_features, columns=features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392e5452-4679-44b1-a123-db941a07c5d5",
   "metadata": {},
   "source": [
    "Splitting Data into Training And Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331411a3-132e-4e59-bb51-42f908a41d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(df_scaled,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa647ed-3685-4749-ad6e-616e908f590d",
   "metadata": {},
   "source": [
    "Finding Optimal K Using Elbow Method Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123dba9e-7f18-4caf-a15d-6f9aa26676e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "inertia = []\n",
    "k_values = range(1,11)\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans= KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(train_data)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(k_values, inertia, marker='o')\n",
    "plt.xlabel(\"Number of Cluster (K)\")\n",
    "plt.ylabel(\"Inertia\")\n",
    "plt.title(\"Elbow Method For Optimal K\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b285ad0-b88d-443c-82c3-90355949ea87",
   "metadata": {},
   "outputs": [],
   "source": [
    "Applying KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c7fd25-2b4e-45d3-9614-e1599a63b143",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_k = 5\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "filtered_df[\"cluster\"] = kmeans.fit_predict(df_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6c96f6-f141-408e-9c0a-2e37cdd67753",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered_df[\"cluster\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86907a75-a809-4b8c-9614-d80929996126",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(df_scaled)\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.scatter(pca_result[:,0],pca_result[:,1], c=filtered_df['cluster'],cmap='viridis')\n",
    "plt.title(\"K-Means Clusters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2b773b-e69d-4102-aed5-d1e3f9ecd7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def recommend_songs(song_name, filtered_df, numerical_features, num_recommendations=5):\n",
    "    # Find song(s) matching the track name\n",
    "    song_data = filtered_df[filtered_df['track_name'] == song_name]\n",
    "    \n",
    "    if song_data.empty:\n",
    "        print(f\"Song '{song_name}' not found.\")\n",
    "        return None\n",
    "    \n",
    "    if len(song_data) > 1:\n",
    "        print(f\"Warning: Multiple songs found for '{song_name}'. Using the first one.\")\n",
    "    \n",
    "    # Use the first matching song\n",
    "    song_row = song_data.iloc[0]\n",
    "    song_cluster = song_row['cluster']\n",
    "\n",
    "    # Filter songs in the same cluster\n",
    "    same_cluster_songs = filtered_df[filtered_df['cluster'] == song_cluster].copy()\n",
    "\n",
    "    # Features for all songs in cluster\n",
    "    cluster_features = same_cluster_songs[numerical_features]\n",
    "\n",
    "    # Features for the selected input song\n",
    "    input_features = song_row[numerical_features].values.reshape(1, -1)\n",
    "\n",
    "    # Compute similarity between input song and cluster songs\n",
    "    similarity_scores = cosine_similarity(input_features, cluster_features).flatten()\n",
    "\n",
    "    # Add similarity scores to DataFrame\n",
    "    same_cluster_songs['similarity'] = similarity_scores\n",
    "\n",
    "    # Exclude the input song itself\n",
    "    recommendations = same_cluster_songs[same_cluster_songs['track_name'] != song_name] \\\n",
    "                        .sort_values(by='similarity', ascending=False) \\\n",
    "                        .head(num_recommendations)\n",
    "\n",
    "    return recommendations[['track_name', 'artist_name', 'genre', 'similarity']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e3df2b-27f5-4475-9cfd-bbf437864cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_song = \"Don't Let Me Be Lonely Tonight\"\n",
    "numerical_features = features  # Adjust to your feature set\n",
    "\n",
    "recommended = recommend_songs(input_song, filtered_df, numerical_features, num_recommendations=5)\n",
    "\n",
    "if recommended is not None:\n",
    "    print(f\"Songs similar to '{input_song}':\")\n",
    "    print(recommended)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fff1ca-2a49-47a3-9099-c140f1f50237",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# choosing unique \n",
    "print(filtered_df['track_name'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbe7fe1-c77f-44a9-aa8d-350e01b8479a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
